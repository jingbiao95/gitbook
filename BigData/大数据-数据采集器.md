## **1 Flume**

Flume作为Hadoop的组件，是由Cloudera专门研发的分布式日志收集系统。

Flume提供了从Console（控制台）、RPC（Thrift-RPC）、Text（文件）、Tail（UNIX Tail）、Syslog、Exec（命令执行）等数据源上收集数据的能力。

Flume采用了多Master的方式。为了保证配置数据的一致性，Flume引入了ZooKeeper，用于保存配置数据。ZooKeeper本身可保证配置数据的一致性和高可用性。另外，在配置数据发生变化时，ZooKeeper可以通知Flume Master节点。Flume Master节点之间使用Gossip协议同步数据。



Flume支持设置Sink的Failover和加载平衡，这样就可以保证在有一个Agent失效的情况下，整个系统仍能正常收集数据。Flume中传输的内容定义为事件（Event），事件由Headers（包含元数据，即Meta Data）和Payload组成。

Flume提供SDK，可以支持用户定制开发。Flume客户端负责在事件产生的源头把事件发送给Flume的Agent。客户端通常和产生数据源的应用在同一个进程空间。常见的Flume 客户端有Avro、Log4J、Syslog和HTTP Post。



## **2 Fluentd**

Fluentd是另一个开源的数据收集架构，如图1所示。Fluentd使用C/Ruby开发，使用JSON文件来统一日志数据。通过丰富的插件，可以收集来自各种系统或应用的日志，然后根据用户定义将日志做分类处理。通过Fluentd，可以非常轻易地实现像追踪日志文件并将其过滤后转存到 MongoDB 这样的操作。Fluentd可以彻底地把人从烦琐的日志处理中解放出来。

![img](https://raw.githubusercontent.com/jingbiao95/Images/main/v2-d99cfabb3e47cf10a923a089c0d97c0a_720w.jpg)



Fluentd具有多个功能特点：安装方便、占用空间小、半结构化数据日志记录、灵活的插件机制、可靠的缓冲、日志转发。Treasure Data公司对该产品提供支持和维护。另外，采用JSON统一数据/日志格式是它的另一个特点。相对Flume，Fluentd配置也相对简单一些。

Fluentd的扩展性非常好，客户可以自己定制（Ruby）Input/Buffer/Output。Fluentd具有跨平台的问题，并不支持Windows平台。

Fluentd的Input/Buffer/Output非常类似于Flume的Source/Channel/Sink。Fluentd架构如图2所示。



![img](https://raw.githubusercontent.com/jingbiao95/Images/main/v2-d4d2fbe364f0bf0a8ceedf662436ea9b_720w.jpg)



## **3 Logstash**

Logstash是著名的开源数据栈ELK（ElasticSearch，Logstash，Kibana）中的那个L。因为Logstash用JRuby开发，所以运行时依赖JVM。Logstash的部署架构如图3所示，当然这只是一种部署的选项。

![img](https://raw.githubusercontent.com/jingbiao95/Images/main/v2-232c1d2d315b65ae5fdb446d2a348858_720w.jpg)



## **4 Chukwa**

Chukwa是Apache旗下另一个开源的数据收集平台，它远没有其他几个有名。Chukwa基于Hadoop的HDFS和MapReduce来构建（用Java来实现），提供扩展性和可靠性。它提供了很多模块以支持Hadoop集群日志分析。Chukwa同时提供对数据的展示、分析和监视。该项目目前已经不活跃。

Chukwa适应以下需求：

（1）灵活的、动态可控的数据源。

（2）高性能、高可扩展的存储系统。

（3）合适的架构，用于对收集到的大规模数据进行分析。

Chukwa架构如图4所示。

![img](https://pic4.zhimg.com/80/v2-054fe3d46fcec5d4c1d6c657453003cb_720w.jpg)

## **5 Scribe**

Scribe是Facebook开发的数据（日志）收集系统。其官网已经多年不维护。Scribe为日志的“分布式收集，统一处理”提供了一个可扩展的，高容错的方案。当中央存储系统的网络或者机器出现故障时，Scribe会将日志转存到本地或者另一个位置；当中央存储系统恢复后，Scribe会将转存的日志重新传输给中央存储系统。Scribe通常与Hadoop结合使用，用于向HDFS中push（推）日志，而Hadoop通过MapReduce作业进行定期处理。

![img](https://raw.githubusercontent.com/jingbiao95/Images/main/v2-1bce60f6365f9db147eb8aa6e9d91fa5_720w.jpg)

## **6 Splunk**

在商业化的大数据平台产品中，Splunk提供完整的数据采集、数据存储、数据分析和处理，以及数据展现的能力。Splunk是一个分布式机器数据平台，主要有三个角色。Splunk架构如图6所示。

![img](https://pic3.zhimg.com/80/v2-d813dbcd273b57be947f86e544f12ede_720w.jpg)

Search：负责数据的搜索和处理，提供搜索时的信息抽取功能。

Indexer：负责数据的存储和索引。

Forwarder：负责数据的收集、清洗、变形，并发送给Indexer。

Splunk内置了对Syslog、TCP/UDP、Spooling的支持，同时，用户可以通过开发 Input和Modular Input的方式来获取特定的数据。在Splunk提供的软件仓库里有很多成熟的数据采集应用，如AWS、数据库（DBConnect）等，可以方便地从云或数据库中获取数据进入Splunk的数据平台做分析。

Search Head和Indexer都支持Cluster的配置，即高可用、高扩展的、但Splunk现在还没有针对Forwarder的Cluster的功能。也就是说，如果有一台Forwarder的机器出了故障，则数据收集也会随之中断，并不能把正在运行的数据收集任务因故障切换（Failover）到其他的Forwarder上。



## **7 Scrapy**

Python的爬虫架构叫Scrapy。Scrapy是由Python语言开发的一个快速、高层次的屏幕抓取和Web抓取架构，用于抓取Web站点并从页面中提取结构化数据。Scrapy的用途广泛，可以用于数据挖掘、监测和自动化测试。

Scrapy吸引人的地方在于它是一个架构，任何人都可以根据需求方便地进行修改。它还提供多种类型爬虫的基类，如BaseSpider、Sitemap爬虫等，最新版本提供对Web 2.0爬虫的支持。

Scrapy运行原理如图7所示。

![img](https://pic3.zhimg.com/80/v2-f33ee3c48892cf722775e49f4560f33e_720w.jpg)

Scrapy的整个数据处理流程由Scrapy引擎进行控制。Scrapy运行流程如下：

（1）Scrapy引擎打开一个域名时，爬虫处理这个域名，并让爬虫获取第一个爬取的URL。

（2）Scrapy引擎先从爬虫那获取第一个需要爬取的URL，然后作为请求在调度中进行调度。

（3）Scrapy引擎从调度那里获取接下来进行爬取的页面。

（4）调度将下一个爬取的URL返回给引擎，引擎将它们通过下载中间件发送到下载器。

（5）当网页被下载器下载完成以后，响应内容通过下载器中间件被发送到Scrapy引擎。

（6）Scrapy引擎收到下载器的响应并将它通过爬虫中间件发送到爬虫进行处理。

（7）爬虫处理响应并返回爬取到的项目，然后给Scrapy引擎发送新的请求。

（8）Scrapy引擎将抓取到的放入项目管道，并向调度器发送请求。

（9）系统重复第（2）步后面的操作，直到调度器中没有请求，然后断开Scrapy引擎与域之间的联系。





## 参考文献

https://zhuanlan.zhihu.com/p/426323026