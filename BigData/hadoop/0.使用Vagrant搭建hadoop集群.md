## 环境准备

### vagrant 环境

vagrant 

## 安装步骤

### 1. 从官网下载centos镜像

```
vagrant box add centos/7
```



### 2.创建vagrantfile所在文件夹，并创建两个文件Vagrantfile和init.sh

#### VagrantFile

```
Vagrant.configure("2") do |config|
    config.vm.provider 'virtualbox' do |vb|
        # 解决DNS问题
        vb.customize ["modifyvm", :id, "--natdnshostresolver1", "on"]
    config.vm.define :master1, primary: true do |master|
        master.vm.provider "virtualbox" do |v|
            v.customize ["modifyvm", :id, "--name", "hadoop-master1", "--memory", "512"]
       end
       master.vm.box = "centos/7"
       master.vm.hostname = "hadoop-master1"
       master.vm.network :private_network, ip: "192.168.10.10"
    end

   (1..3).each do |i|
    config.vm.define "slave#{i}" do |node|
        node.vm.box = "centos/7"
        node.vm.hostname = "hadoop-slave#{i}"
        node.vm.network :private_network, ip: "192.168.10.1#{i}"
        node.vm.provider "virtualbox" do |vb|
          v.customize ["modifyvm", :id, "--name", "hadoop-slave#{i}"]
          vb.memory = "1024"
        end
     end
   end

  #manage hosts file 
  config.hostmanager.enabled = true
  config.hostmanager.manage_host = true
  config.hostmanager.manage_guest = true

   #provision
   config.vm.provision "shell", path: "init.sh", privileged: false
end
```

可以看到， 我们一共创建了3个虚拟机环境 ，分别是master1, slave1, slave2,slave3



#### init.sh

```sh
sudo yum install -y epel-release
sudo yum update -y
sudo yum install -y lrzsz.x86_64
sudo yum install -y nmap-ncat.x86_64
sudo yum install -y net-tools
sudo yum install -y vim-enhanced.x86_64
sudo yum install -y sshpass
sudo yum install -y java-1.8.0-openjdk-devel
```



### 3.启动虚拟机

```
vagrant up
```

### 4.设置ssh互信

在ssh登录过程中，可能会报Permission denied (publickey,gssapi-keyex,gssapi-with-mic)，

依次进入虚拟中,在所以虚拟机中都需要配置

```
vagrant ssh hadoop-master1  # 登录进虚拟机中
vagrant ssh hadoop-slave1 
vagrant ssh hadoop-slave2 
vagrant ssh hadoop-slave3 
```

解决方法如下：`sudo vim /etc/ssh/sshd_config`, 修改如下配置为yes

```undefined
PubkeyAuthentication yes
PasswordAuthentication yes
```

重启`systemctl restart sshd`



### 5.编写集群分发脚本xsync

```bash
cd /home/vagrant

vim xsync
```

xsync文件

```sh
#!/bin/bash

#1. 判断参数个数
if [ $# -lt 1 ]
then
    echo Not Enough Arguement!
    exit;
fi
#2. 遍历集群所有机器
for host in hadoop-master1 hadoop-slave1 hadoop-slave2
do
    echo ====================  $host  ====================
    #3. 遍历所有目录，挨个发送

    for file in $@
    do
        #4. 判断文件是否存在
        if [ -e $file ]
            then
                #5. 获取父目录
                pdir=$(cd -P $(dirname $file); pwd)

                #6. 获取当前文件的名称
                fname=$(basename $file)
                ssh $host "mkdir -p $pdir"
                rsync -av $pdir/$fname $host:$pdir
            else
                echo $file does not exists!
        fi
    done
done
```

修改脚本 xsync 具有执行权限

```bash
chmod +x xsync
```

###  6.SSH无密登录配置

vagrant创建虚拟机默认用户/密码：

```
root/vagrant
vagrant/vagrant
```



在vagrant用户登录情况下

```bash
ssh-keygen -t rsa
ssh-copy-id hadoop-master1
ssh-copy-id  hadoop-slave1 
ssh-copy-id  hadoop-slave2
# 命令期间需要输入vagrant用户的密码：vagrant
```

切换到root用户

```bash
ssh-keygen -t rsa
ssh-copy-id hadoop-master1
ssh-copy-id  hadoop-slave1 
ssh-copy-id  hadoop-slave2
# 命令期间需要输入root用户的密码：vagrant
```

还需要在hadoop-slave1、hadoop-slave2上采用vagrant账号配置一下无密登录到hadoop-master1、hadoop-slave1、hadoop-slave2服务器上。



### 7.配置JDK环境变量

#### 安装jdk

**测试JDK**

`java -version`

没有则安装

`export JAVA_HOME=/usr/lib/jvm/java-1.8.0-openjdk-1.8.0.171-8.b10.el7_5.x86_64`

#### 环境变量文件

新建/etc/profile.d/my_env.sh文件

```
sudo vim /etc/profile.d/my_env.sh
```

添加如下内容

```sh
#JAVA_HOME
export JAVA_HOME=/usr/lib/jvm/java-1.8.0-openjdk-1.8.0.171-8.b10.el7_5.x86_64
export PATH=$PATH:$JAVA_HOME/bin
```

source一下/etc/profile文件，让新的环境变量PATH生效

`source /etc/profile`

### 8.安装hadoop

#### 下载hadoop

Hadoop下载地址：https://archive.apache.org/dist/hadoop/common/hadoop-3.1.3/

将hadoop-3.1.3.tar.gz下载下来并上传到master1的/home/vagrant目录下

#### 解压安装文件

` tar -zxvf hadoop-3.1.3.tar.gz`

#### hadoop环境变量

`sudo vim /etc/profile.d/my_env.sh`

```sh
# HADOOP_HOME
export HADOOP_HOME=/home/vagrant/hadoop-3.1.3
export PATH=$PATH:$HADOOP_HOME/bin
export PATH=$PATH:$HADOOP_HOME/sbin
```

` source /etc/profile`

#### 测试是否安装成功

`hadoop version`

### 9. hadoop集群配置

一共需要配置4个文件， core-site.xml hdfs-site.xml yarn-site.xml mappr-site.xml workers, 以上文件路径都位于etc/hadoop/中

#### 集群部署规划

|      | hadoop-master          | hadoop-slave1                    | hadoop-slave2                   |
| ---- | ---------------------- | -------------------------------- | ------------------------------- |
| HDFS | NameNode<br />DataNode | DataNode                         | SecondaryNameNode<br />DataNode |
| YARN | NodeManager            | ResourceManager<br />NodeManager | NodeManager                     |





`cd /home/vagrant/hadoop-3.1.3/etc/hadoop/`

#### core-site.xml 核心配置文件

```xml
<configuration>
<!-- 设置 resourcemanager 在哪个节点-->
<!-- Site specific YARN configuration properties -->
    <property>
        <name>yarn.resourcemanager.hostname</name>
        <value>hadoop-master1</value>
    </property>
    <property>
        <name>yarn.resourcemanager.webapp.address</name>
        <value>192.168.10.10:8088</value>
    </property>
    <!-- reducer取数据的方式是mapreduce_shuffle -->
    <property>
        <name>yarn.nodemanager.aux-services</name>
        <value>mapreduce_shuffle</value>
    </property>
</configuration>
```

#### hdfs-site.xml

```xml
<configuration>
        <!-- 设置namenode的http通讯地址 -->
        <property>
                <name>dfs.namenode.secondary.http-address</name>
                <value>hadoop-master1:50090</value>
        </property>
        <!-- 设置hdfs副本数量 -->
        <property>
                <name>dfs.replication</name>
                <value>2</value>
        </property>
         <!-- 设置namenode存放的路径 -->
        <property>
                <name>dfs.namenode.name.dir</name>
                <value>file:/home/vagrant/hadoop-3.0.3/tmp/dfs/name</value>
        </property>
         <!-- 设置datanode存放的路径 -->
        <property>
                <name>dfs.datanode.data.dir</name>
                <value>file:/home/vagrant/hadoop-3.0.3/tmp/dfs/data</value>
        </property>
        <property>
          <name>dfs.namenode.datanode.registration.ip-hostname-check</name>
          <value>false</value>
        </property>
</configuration>
```

#### yarn-site.xml

```xml
<configuration>
        <property>
                <name>yarn.resourcemanager.hostname</name>
                <value>hadoop-master1</value>
        </property>
        <property>
          <name>yarn.resourcemanager.webapp.address</name>
          <value>192.168.10.10:8088</value>
         </property>
         <!-- reducer取数据的方式是mapreduce_shuffle -->
        <property>
                <name>yarn.nodemanager.aux-services</name>
                <value>mapreduce_shuffle</value>
        </property>
</configuration>
```



#### mapred-site.xml

```xml
<configuration>
        <!-- 通知框架MR使用YARN -->
        <property>
                <name>mapreduce.framework.name</name>
                <value>yarn</value>
        </property>
</configuration>
```

#### workers

```
hadoop-slave1
hadoop-slave2
```

### 10 启动集群

***\*如果集群是第一次启动\****，需要在hadoop102节点格式化NameNode（注意：格式化NameNode，会产生新的集群id，导致NameNode和DataNode的集群id不一致，集群找不到已往数据。如果集群在运行过程中报错，需要重新格式化NameNode的话，一定要先停止namenode和datanode进程，并且要删除所有机器的data和logs目录，然后再进行格式化。）

` hdfs namenode -format`

#### 启动HDFS

`sbin/start-dfs.sh`

####  启动YARN

在配置了ResourceManager的节点（hadoop-slave1) 启动YARN

`sbin/start-yarn.sh`

#### Web端查看HDFS的NameNode

（a）浏览器中输入：http://192.168.10.10:9870/

（b）查看HDFS上存储的数据信息



#### Web端查看YARN的ResourceManager

（a）浏览器中输入：http://192.168.10.11:8088

（b）查看YARN上运行的Job信息



### 11 集群基本测试

上传文件到集群



```bash
hadoop fs -mkdir /input

hadoop fs -put $HADOOP_HOME/wcinput/word.txt /input
```

 查看HDFS文件存储路径

```
```

查看HDFS在磁盘存储文件内容

```
```

### 12 配置历史服务器

为了查看程序的历史运行情况，需要配置一下历史服务器。具体配置步骤如下：

#### 配置mapred-site.xml

` vim mapred-site.xml`

在该文件里面增加如下配置。

```xml
<!-- 历史服务器端地址 -->
<property>
    <name>mapreduce.jobhistory.address</name>
    <value>hadoop102:10020</value>
</property>

<!-- 历史服务器web端地址 -->
<property>
    <name>mapreduce.jobhistory.webapp.address</name>
    <value>hadoop102:19888</value>
</property>
```

#### 分发配置

`xsync $HADOOP_HOME/etc/hadoop/mapred-site.xml`



在hadoop-master1启动历史服务器

`mapred --daemon start historyserver`

查看历史服务器是否启动

`jps`

***\*查看JobHistory\****

http://192.168.10.10:19888/jobhistory



## 参考文献 

https://www.jianshu.com/p/670b7fa28e08

